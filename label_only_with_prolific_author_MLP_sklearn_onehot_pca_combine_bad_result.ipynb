{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["2TxMb7SSSh94","c08IV6f5Scod","NoQamYaVSoBZ","rlyRGDfNUNJu"],"authorship_tag":"ABX9TyNXBscuQpYIRnJlMfoeoG12"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"FVohdw7E6ltN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664448840562,"user_tz":-600,"elapsed":20522,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"dd1e2632-d1e2-4424-8c34-faf7b1e71dfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GCmE5ssApxVJ","executionInfo":{"status":"ok","timestamp":1664448932506,"user_tz":-600,"elapsed":477,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"4ea19200-cfe7-49d9-f292-aa6a329f09d0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep 29 10:55:31 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"id":"Ak8dAQ7zp59_","executionInfo":{"status":"ok","timestamp":1664448934768,"user_tz":-600,"elapsed":1286,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"4ceb14f9-4bf0-478d-8d8d-df59ce6bd061","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"code","source":["import json\n","import ast\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","import sklearn.preprocessing as preprocessing\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.multioutput import ClassifierChain\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.naive_bayes import GaussianNB,MultinomialNB\n","from sklearn.metrics import accuracy_score,hamming_loss\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","from sklearn.decomposition import TruncatedSVD \n","from sklearn.decomposition import PCA\n","\n","\n","\n","#embedding\n","from gensim.models import Word2Vec\n","\n","# tqdm\n","from tqdm.notebook import tqdm\n","\n"],"metadata":{"id":"eACz6nmU66Rr","executionInfo":{"status":"ok","timestamp":1664448936029,"user_tz":-600,"elapsed":1263,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_file_path = \"/content/drive/MyDrive/assign2/comp90051-22-s2-authorship/train.json\"\n","test_file_path = \"/content/drive/MyDrive/assign2/comp90051-22-s2-authorship/test.json\"\n","\n","with open(train_file_path, 'r') as f:\n","    data = json.load(f)\n","df_train = pd.DataFrame(data)\n","\n","with open(test_file_path, 'r') as f:\n","    data = json.load(f)\n","df_test = pd.DataFrame(data)"],"metadata":{"id":"NUUlbazb66Un","executionInfo":{"status":"ok","timestamp":1664450728926,"user_tz":-600,"elapsed":1476,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# Retrive the non-prolific author and prolific author index\n","non_prolific_author_index = []\n","prolific_author_index = []\n","for i,j in enumerate(df_train['authors']):\n","  sum = 0\n","  for k in j:\n","    if k < 100 and k >= 0:\n","      sum += 1\n","  if sum == 0:\n","    non_prolific_author_index.append(i)\n","  else:\n","    prolific_author_index.append(i)\n","\n","df_non_prolifc_authors = df_train.drop(prolific_author_index)\n","df_prolific_authors = df_train.drop(non_prolific_author_index)"],"metadata":{"id":"SWQ40mAU66Z_","executionInfo":{"status":"ok","timestamp":1664450728927,"user_tz":-600,"elapsed":4,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["df_prolific_authors"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"qIjtUz5H66h3","executionInfo":{"status":"ok","timestamp":1664450728927,"user_tz":-600,"elapsed":4,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"225d0d9c-7dc4-44f3-b1ff-2c938d7bb776"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              authors  year  \\\n","0                     [42, 13720, 36]     9   \n","1                   [1359, 15881, 45]    15   \n","3                                [97]    10   \n","4                          [19617, 2]    10   \n","9                 [9641, 44, 5623, 2]    18   \n","...                               ...   ...   \n","25767               [19974, 68, 8903]     1   \n","25776  [6353, 67, 3037, 15856, 13521]    10   \n","25778          [7686, 3810, 87, 7451]    16   \n","25781                     [14864, 92]    16   \n","25788                      [1797, 78]    14   \n","\n","                                                abstract venue  \\\n","0      [2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...    20   \n","1      [40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...     2   \n","3      [46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...     4   \n","4      [37, 3709, 3836, 1586, 2151, 1727, 3021, 1860,...     9   \n","9      [1731, 2021, 1543, 11, 1546, 11, 1647, 2163, 1...     0   \n","...                                                  ...   ...   \n","25767  [40, 1542, 1691, 2449, 1535, 2855, 1549, 1755,...    23   \n","25776  [40, 1542, 1691, 2907, 1540, 1535, 2121, 2431,...    10   \n","25778  [2144, 1661, 2151, 1966, 3776, 4864, 1546, 219...    31   \n","25781  [37, 1662, 33, 1814, 2036, 1692, 1553, 2333, 2...     0   \n","25788  [46, 1605, 1681, 10, 1557, 4741, 1535, 2021, 1...     1   \n","\n","                                                   title  \n","0      [41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...  \n","1      [1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...  \n","3      [40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...  \n","4      [38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...  \n","9      [1560, 1694, 11, 1546, 11, 3066, 1728, 47, 160...  \n","...                                                  ...  \n","25767  [1708, 33, 58, 57, 2174, 1548, 1538, 1553, 359...  \n","25776  [53, 2555, 4480, 1535, 1637, 1898, 1549, 53, 3...  \n","25778  [1615, 1966, 11, 3238, 1653, 3318, 24, 2144, 1...  \n","25781  [46, 1670, 1826, 37, 1632, 46, 1991, 1525, 152...  \n","25788  [46, 1910, 36, 2107, 1547, 1553, 1716, 1528, 5...  \n","\n","[7460 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-6e5bd86f-9996-42cf-bbca-4c20c5e68033\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>authors</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>venue</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[42, 13720, 36]</td>\n","      <td>9</td>\n","      <td>[2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...</td>\n","      <td>20</td>\n","      <td>[41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[1359, 15881, 45]</td>\n","      <td>15</td>\n","      <td>[40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...</td>\n","      <td>2</td>\n","      <td>[1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[97]</td>\n","      <td>10</td>\n","      <td>[46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...</td>\n","      <td>4</td>\n","      <td>[40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[19617, 2]</td>\n","      <td>10</td>\n","      <td>[37, 3709, 3836, 1586, 2151, 1727, 3021, 1860,...</td>\n","      <td>9</td>\n","      <td>[38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>[9641, 44, 5623, 2]</td>\n","      <td>18</td>\n","      <td>[1731, 2021, 1543, 11, 1546, 11, 1647, 2163, 1...</td>\n","      <td>0</td>\n","      <td>[1560, 1694, 11, 1546, 11, 3066, 1728, 47, 160...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>25767</th>\n","      <td>[19974, 68, 8903]</td>\n","      <td>1</td>\n","      <td>[40, 1542, 1691, 2449, 1535, 2855, 1549, 1755,...</td>\n","      <td>23</td>\n","      <td>[1708, 33, 58, 57, 2174, 1548, 1538, 1553, 359...</td>\n","    </tr>\n","    <tr>\n","      <th>25776</th>\n","      <td>[6353, 67, 3037, 15856, 13521]</td>\n","      <td>10</td>\n","      <td>[40, 1542, 1691, 2907, 1540, 1535, 2121, 2431,...</td>\n","      <td>10</td>\n","      <td>[53, 2555, 4480, 1535, 1637, 1898, 1549, 53, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>25778</th>\n","      <td>[7686, 3810, 87, 7451]</td>\n","      <td>16</td>\n","      <td>[2144, 1661, 2151, 1966, 3776, 4864, 1546, 219...</td>\n","      <td>31</td>\n","      <td>[1615, 1966, 11, 3238, 1653, 3318, 24, 2144, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>25781</th>\n","      <td>[14864, 92]</td>\n","      <td>16</td>\n","      <td>[37, 1662, 33, 1814, 2036, 1692, 1553, 2333, 2...</td>\n","      <td>0</td>\n","      <td>[46, 1670, 1826, 37, 1632, 46, 1991, 1525, 152...</td>\n","    </tr>\n","    <tr>\n","      <th>25788</th>\n","      <td>[1797, 78]</td>\n","      <td>14</td>\n","      <td>[46, 1605, 1681, 10, 1557, 4741, 1535, 2021, 1...</td>\n","      <td>1</td>\n","      <td>[46, 1910, 36, 2107, 1547, 1553, 1716, 1528, 5...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7460 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e5bd86f-9996-42cf-bbca-4c20c5e68033')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6e5bd86f-9996-42cf-bbca-4c20c5e68033 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6e5bd86f-9996-42cf-bbca-4c20c5e68033');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["# Retrieve the prolific author as label\n","prolific_author_label = []\n","non_prolific_author_label = []\n","for i in df_prolific_authors['authors']:\n","  prolific_author_label_each_instance = []\n","  non_prolific_author_label_each_instance = []\n","  for j in i:\n","    if j >= 0 and j < 100:\n","      prolific_author_label_each_instance.append(j)\n","    else:\n","      non_prolific_author_label_each_instance.append(j)\n","  prolific_author_label.append(prolific_author_label_each_instance)\n","  non_prolific_author_label.append(non_prolific_author_label_each_instance)\n","\n","\n","df_prolific_authors['coauthors'] = non_prolific_author_label"],"metadata":{"id":"eBnMxF_x66kd","executionInfo":{"status":"ok","timestamp":1664450728927,"user_tz":-600,"elapsed":3,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["#One-hot encoding the labels\n","multilable_binarizer = MultiLabelBinarizer()\n","ohe_prolific_labels = multilable_binarizer.fit_transform(prolific_author_label).astype('float')"],"metadata":{"id":"8nQCgBfq66nI","executionInfo":{"status":"ok","timestamp":1664450728927,"user_tz":-600,"elapsed":3,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# df_prolific_authors['sentences'] = df_prolific_authors['title'] + df_prolific_authors['abstract'] \n","# df_prolific_authors = df_prolific_authors.drop(['abstract','title'],axis = 1)\n","\n","# df_test['sentences'] = df_test['title'] + df_test['abstract'] \n","# df_test = df_test.drop(['abstract','title'],axis = 1)"],"metadata":{"id":"9YANSMF-66oa","executionInfo":{"status":"ok","timestamp":1664450728927,"user_tz":-600,"elapsed":3,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["df_prolific_authors"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"fSXkRWXr66pr","executionInfo":{"status":"ok","timestamp":1664450729485,"user_tz":-600,"elapsed":5,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"4b5301ee-18a9-46ef-f447-f1ff631ad35d"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              authors  year  \\\n","0                     [42, 13720, 36]     9   \n","1                   [1359, 15881, 45]    15   \n","3                                [97]    10   \n","4                          [19617, 2]    10   \n","9                 [9641, 44, 5623, 2]    18   \n","...                               ...   ...   \n","25767               [19974, 68, 8903]     1   \n","25776  [6353, 67, 3037, 15856, 13521]    10   \n","25778          [7686, 3810, 87, 7451]    16   \n","25781                     [14864, 92]    16   \n","25788                      [1797, 78]    14   \n","\n","                                                abstract venue  \\\n","0      [2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...    20   \n","1      [40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...     2   \n","3      [46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...     4   \n","4      [37, 3709, 3836, 1586, 2151, 1727, 3021, 1860,...     9   \n","9      [1731, 2021, 1543, 11, 1546, 11, 1647, 2163, 1...     0   \n","...                                                  ...   ...   \n","25767  [40, 1542, 1691, 2449, 1535, 2855, 1549, 1755,...    23   \n","25776  [40, 1542, 1691, 2907, 1540, 1535, 2121, 2431,...    10   \n","25778  [2144, 1661, 2151, 1966, 3776, 4864, 1546, 219...    31   \n","25781  [37, 1662, 33, 1814, 2036, 1692, 1553, 2333, 2...     0   \n","25788  [46, 1605, 1681, 10, 1557, 4741, 1535, 2021, 1...     1   \n","\n","                                                   title  \\\n","0      [41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...   \n","1      [1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...   \n","3      [40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...   \n","4      [38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...   \n","9      [1560, 1694, 11, 1546, 11, 3066, 1728, 47, 160...   \n","...                                                  ...   \n","25767  [1708, 33, 58, 57, 2174, 1548, 1538, 1553, 359...   \n","25776  [53, 2555, 4480, 1535, 1637, 1898, 1549, 53, 3...   \n","25778  [1615, 1966, 11, 3238, 1653, 3318, 24, 2144, 1...   \n","25781  [46, 1670, 1826, 37, 1632, 46, 1991, 1525, 152...   \n","25788  [46, 1910, 36, 2107, 1547, 1553, 1716, 1528, 5...   \n","\n","                        coauthors  \n","0                         [13720]  \n","1                   [1359, 15881]  \n","3                              []  \n","4                         [19617]  \n","9                    [9641, 5623]  \n","...                           ...  \n","25767               [19974, 8903]  \n","25776  [6353, 3037, 15856, 13521]  \n","25778          [7686, 3810, 7451]  \n","25781                     [14864]  \n","25788                      [1797]  \n","\n","[7460 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-0d0f9325-d259-4093-a844-d8cba6f8327c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>authors</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>venue</th>\n","      <th>title</th>\n","      <th>coauthors</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[42, 13720, 36]</td>\n","      <td>9</td>\n","      <td>[2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...</td>\n","      <td>20</td>\n","      <td>[41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...</td>\n","      <td>[13720]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[1359, 15881, 45]</td>\n","      <td>15</td>\n","      <td>[40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...</td>\n","      <td>2</td>\n","      <td>[1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...</td>\n","      <td>[1359, 15881]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[97]</td>\n","      <td>10</td>\n","      <td>[46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...</td>\n","      <td>4</td>\n","      <td>[40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[19617, 2]</td>\n","      <td>10</td>\n","      <td>[37, 3709, 3836, 1586, 2151, 1727, 3021, 1860,...</td>\n","      <td>9</td>\n","      <td>[38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...</td>\n","      <td>[19617]</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>[9641, 44, 5623, 2]</td>\n","      <td>18</td>\n","      <td>[1731, 2021, 1543, 11, 1546, 11, 1647, 2163, 1...</td>\n","      <td>0</td>\n","      <td>[1560, 1694, 11, 1546, 11, 3066, 1728, 47, 160...</td>\n","      <td>[9641, 5623]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>25767</th>\n","      <td>[19974, 68, 8903]</td>\n","      <td>1</td>\n","      <td>[40, 1542, 1691, 2449, 1535, 2855, 1549, 1755,...</td>\n","      <td>23</td>\n","      <td>[1708, 33, 58, 57, 2174, 1548, 1538, 1553, 359...</td>\n","      <td>[19974, 8903]</td>\n","    </tr>\n","    <tr>\n","      <th>25776</th>\n","      <td>[6353, 67, 3037, 15856, 13521]</td>\n","      <td>10</td>\n","      <td>[40, 1542, 1691, 2907, 1540, 1535, 2121, 2431,...</td>\n","      <td>10</td>\n","      <td>[53, 2555, 4480, 1535, 1637, 1898, 1549, 53, 3...</td>\n","      <td>[6353, 3037, 15856, 13521]</td>\n","    </tr>\n","    <tr>\n","      <th>25778</th>\n","      <td>[7686, 3810, 87, 7451]</td>\n","      <td>16</td>\n","      <td>[2144, 1661, 2151, 1966, 3776, 4864, 1546, 219...</td>\n","      <td>31</td>\n","      <td>[1615, 1966, 11, 3238, 1653, 3318, 24, 2144, 1...</td>\n","      <td>[7686, 3810, 7451]</td>\n","    </tr>\n","    <tr>\n","      <th>25781</th>\n","      <td>[14864, 92]</td>\n","      <td>16</td>\n","      <td>[37, 1662, 33, 1814, 2036, 1692, 1553, 2333, 2...</td>\n","      <td>0</td>\n","      <td>[46, 1670, 1826, 37, 1632, 46, 1991, 1525, 152...</td>\n","      <td>[14864]</td>\n","    </tr>\n","    <tr>\n","      <th>25788</th>\n","      <td>[1797, 78]</td>\n","      <td>14</td>\n","      <td>[46, 1605, 1681, 10, 1557, 4741, 1535, 2021, 1...</td>\n","      <td>1</td>\n","      <td>[46, 1910, 36, 2107, 1547, 1553, 1716, 1528, 5...</td>\n","      <td>[1797]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7460 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d0f9325-d259-4093-a844-d8cba6f8327c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0d0f9325-d259-4093-a844-d8cba6f8327c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0d0f9325-d259-4093-a844-d8cba6f8327c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["def convert_to_string(df):\n","  total_list = []\n","  for i in df:\n","    per_instance = []\n","    for j in i:\n","      per_instance.append(str(j))\n","    total_list.append(per_instance)\n","  return total_list\n","\n","# word to vec title model\n","string_title = convert_to_string(df_train['title'])\n","# Word2Vec\n","model_title = Word2Vec(string_title, min_count=1)\n","print(model_title)\n","\n","# word to vec abstract model\n","string_abstract = convert_to_string(df_train['abstract'])\n","# Word2Vec\n","model_abstract = Word2Vec(string_abstract, min_count=1)\n","print(model_abstract)\n","\n","\n","# word to vec coauthor model\n","string_coauthor = convert_to_string(df_train['authors'])\n","\n","model_coauthor = Word2Vec(string_coauthor, min_count=1)\n","print(model_coauthor)\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"p1qh7XJY66q-","executionInfo":{"status":"ok","timestamp":1664450750018,"user_tz":-600,"elapsed":20536,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"87d1c06e-ebd0-493e-ae89-0f4e5cba0f13"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Word2Vec(vocab=3444, size=100, alpha=0.025)\n","Word2Vec(vocab=4845, size=100, alpha=0.025)\n","Word2Vec(vocab=20433, size=100, alpha=0.025)\n"]}]},{"cell_type":"markdown","source":["## title and abstract word to embedding"],"metadata":{"id":"qMpB9-gKFj1U"}},{"cell_type":"code","source":["# # title embedding\n","# prolific_author_string_title = convert_to_string(df_prolific_authors['title'])\n","# title_embedding = []\n","# for i in tqdm(prolific_author_string_title):\n","#   temp = np.zeros((len(i),100))\n","#   for k, j in enumerate(i):\n","#     temp[k,:] = model_title[j]\n","#   title_embedding.append(temp.mean(axis=0))\n","\n","\n","# # abstract embedding\n","# prolific_author_string_abstract = convert_to_string(df_prolific_authors['abstract'])\n","# abstract_embedding = []\n","# for i in tqdm(prolific_author_string_abstract):\n","#   temp = np.zeros((len(i),100))\n","#   for k, j in enumerate(i):\n","#     temp[k,:] = model_abstract[j]\n","#   abstract_embedding.append(temp.mean(axis=0))\n","\n","\n","\n","\n","\n","# # coauthor embedding\n","# prolific_author_string_coauthor = convert_to_string(df_prolific_authors['coauthors'])\n","# coauthor_embedding = []\n","# for i in tqdm(prolific_author_string_coauthor):\n","#   temp = np.zeros((len(i),100))\n","#   for k, j in enumerate(i):\n","#     temp[k,:] = model_coauthor[j]\n","#   coauthor_embedding.append(temp.mean(axis=0))\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"PRUu0CXmMxTr","executionInfo":{"status":"ok","timestamp":1664450750019,"user_tz":-600,"elapsed":8,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["## counter vectorizer"],"metadata":{"id":"AQmEWaU0fOly"}},{"cell_type":"code","source":["# counts for abstract, title and coauthor\n","def convert_to_instance_string(df):\n","  total_list = []\n","  for i in df:\n","    total_list.append(str(i)[1:-1].replace(\",\", \"\"))\n","  return total_list\n","\n","# Counts for abstract\n","abstract_voc = {}\n","abstract_num = 4999\n","for i in range(abstract_num):\n","  abstract_voc[str(i)] = i\n","\n","\n","\n","\n","prolific_author_string_abstract = convert_to_instance_string(df_prolific_authors['abstract'])\n","abstract_vectorizer = CountVectorizer(vocabulary = abstract_voc)\n","abstract_counts = abstract_vectorizer.fit_transform(prolific_author_string_abstract)\n","abstract_counts = abstract_counts.toarray()\n","\n","\n","\n","# Counts for title\n","title_voc = {}\n","title_num = 4999\n","for i in range(title_num):\n","  title_voc[str(i)] = i\n","\n","\n","\n","\n","prolific_author_string_title = convert_to_instance_string(df_prolific_authors['title'])\n","title_vectorizer = CountVectorizer(vocabulary = title_voc)\n","title_counts = title_vectorizer.fit_transform(prolific_author_string_title)\n","title_counts = title_counts.toarray()\n","\n","\n","# Counts for coauthor\n","\n","coauthor_voc = {}\n","coauthor_num = 21246\n","for i in range(coauthor_num):\n","  coauthor_voc[str(i)] = i\n","\n","prolific_author_string_coauthors = convert_to_instance_string(df_prolific_authors['coauthors'])\n","coauthor_vectorizer = CountVectorizer(vocabulary = coauthor_voc)\n","coauthor_counts = coauthor_vectorizer.fit_transform(prolific_author_string_coauthors)\n","coauthor_counts = coauthor_counts.toarray()\n","\n","\n"],"metadata":{"id":"evy8tsKlAYch","executionInfo":{"status":"ok","timestamp":1664450750969,"user_tz":-600,"elapsed":955,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["abstract_counts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ex27Ll-6auX","executionInfo":{"status":"ok","timestamp":1664450750969,"user_tz":-600,"elapsed":4,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"605e7f52-a645-47b5-a1cb-e3aa86988226"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]])"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["## PCA for counted-based abstract and title"],"metadata":{"id":"ExPJz6EYEcKV"}},{"cell_type":"code","source":["\n","\n","# svd_abstract = TruncatedSVD(n_components=200)\n","# svd_count_abstract = svd_abstract.fit_transform(abstract_counts)\n","\n","\n","\n","# svd_title = TruncatedSVD(n_components=100)\n","# svd_count_title = svd_title.fit_transform(title_counts)\n","\n","\n","\n","# svd_coauthor = TruncatedSVD(n_components=100)\n","# svd_count_coauthor = svd_coauthor.fit_transform(coauthor_counts)\n","\n","\n","pca_200 = PCA(n_components= 200)\n","pca_count_abstract = pca_200.fit_transform(abstract_counts)\n","\n","pca_100 = PCA(n_components= 100)\n","pca_count_title = pca_100.fit_transform(title_counts)\n","\n","\n","pca_count_coauthor = pca_100.fit_transform(coauthor_counts)\n"],"metadata":{"id":"Nqn5iTkCAdcn","executionInfo":{"status":"ok","timestamp":1664450771840,"user_tz":-600,"elapsed":20873,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["## svd counts abstract and title"],"metadata":{"id":"ZSdMls1AFMlT"}},{"cell_type":"code","source":["# counter vectorized features\n","\n","\n","\n","coauthors_features_name = ['coauthors_' + str(i) for i in range(100)]\n","df_coauthors_features = pd.DataFrame(pca_count_coauthor)\n","df_coauthors_features = df_coauthors_features.astype('float')\n","df_coauthors_features.columns = coauthors_features_name\n","\n","\n","abstract_features_name = ['abstract_' + str(i) for i in range(200)]\n","df_abstract_features = pd.DataFrame(pca_count_abstract)\n","df_abstract_features = df_abstract_features.astype('float')\n","df_abstract_features.columns = abstract_features_name\n","\n","title_features_name = ['title_' + str(i) for i in range(100)]\n","df_title_features = pd.DataFrame(pca_count_title)\n","df_title_features = df_title_features.astype('float')\n","df_title_features.columns = title_features_name\n"],"metadata":{"id":"cb1F7AnaD8cK","executionInfo":{"status":"ok","timestamp":1664450771846,"user_tz":-600,"elapsed":31,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["df_merge_coauthors_sentences = pd.concat([df_coauthors_features, df_title_features,df_abstract_features], axis = 1)"],"metadata":{"id":"psnvl3O9D8-A","executionInfo":{"status":"ok","timestamp":1664450771846,"user_tz":-600,"elapsed":29,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["df_merge_coauthors_sentences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"0IbR6a2ct1M0","executionInfo":{"status":"ok","timestamp":1664450771847,"user_tz":-600,"elapsed":30,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"fcdd0ad8-7619-4de4-f7a8-09ea881ee46b"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      coauthors_0  coauthors_1  coauthors_2  coauthors_3  coauthors_4  \\\n","0       -0.009571    -0.002846    -0.008844    -0.000511    -0.001075   \n","1       -0.011007    -0.003905    -0.012550    -0.000712    -0.001495   \n","2       -0.009434    -0.002798    -0.008725    -0.000478    -0.000973   \n","3       -0.009921    -0.003203    -0.009576    -0.000076    -0.001061   \n","4       -0.010378    -0.004540    -0.012820    -0.000562    -0.001430   \n","...           ...          ...          ...          ...          ...   \n","7455    -0.009283    -0.005068    -0.005012    -0.001051    -0.002071   \n","7456    -0.009852    -0.003023    -0.009470    -0.000521    -0.001063   \n","7457     0.092097     0.059339    -0.050990     0.001464    -0.005062   \n","7458    -0.010877    -0.003379    -0.009356    -0.002581    -0.002564   \n","7459    -0.010034    -0.003400    -0.010397     0.000264    -0.001215   \n","\n","      coauthors_5  coauthors_6  coauthors_7  coauthors_8  coauthors_9  ...  \\\n","0       -0.001923    -0.006986     0.000874    -0.000477     0.000430  ...   \n","1       -0.003017    -0.009968     0.001208    -0.000901     0.000935  ...   \n","2       -0.001885    -0.006686     0.000754    -0.000503     0.000484  ...   \n","3       -0.001889    -0.007728     0.000643    -0.001342    -0.000928  ...   \n","4       -0.003136    -0.010055     0.001154     0.001767     0.001176  ...   \n","...           ...          ...          ...          ...          ...  ...   \n","7455    -0.005167    -0.011075    -0.003089    -0.000469     0.021100  ...   \n","7456    -0.002067    -0.007342     0.000830    -0.000558     0.000540  ...   \n","7457     0.027925    -0.003616     0.025550    -0.016458     0.019490  ...   \n","7458    -0.003929    -0.010583    -0.000069    -0.000409    -0.001764  ...   \n","7459    -0.001599    -0.009451    -0.000754    -0.004186    -0.007637  ...   \n","\n","      abstract_190  abstract_191  abstract_192  abstract_193  abstract_194  \\\n","0        -0.316160      0.556565      0.194132     -0.410025     -0.349819   \n","1         0.124113      0.142072      0.247351      0.190889      0.516250   \n","2        -0.299515     -0.038687     -0.270053     -0.286963     -0.070599   \n","3         0.384354      0.188743      0.227883     -0.687872      0.563455   \n","4         0.870087      0.495401     -0.001753     -0.538688     -0.053328   \n","...            ...           ...           ...           ...           ...   \n","7455      0.024630      0.372056     -0.389966      0.100623     -0.315273   \n","7456      0.588100     -0.366446     -0.406382     -0.143317      0.314082   \n","7457      1.073664     -0.396448     -0.107901      1.289523      0.272125   \n","7458     -0.213597     -0.007666      0.129398      0.164094     -0.270876   \n","7459     -0.746779      0.302515      0.216772      0.040022     -0.459893   \n","\n","      abstract_195  abstract_196  abstract_197  abstract_198  abstract_199  \n","0        -0.085313      0.577743      0.023656      0.123779      0.451074  \n","1         0.441111     -0.146353      0.278677     -0.005393      0.177249  \n","2        -0.218529     -0.031311      0.447944     -0.078734      0.306917  \n","3         0.179416      0.207539     -0.204147      0.209244     -0.301667  \n","4        -0.016859      0.220541     -1.012202     -0.373231      1.549151  \n","...            ...           ...           ...           ...           ...  \n","7455      0.166802     -0.004482      0.113307      0.450305     -0.196696  \n","7456     -0.302000     -0.349476      0.570553      0.615917      0.461205  \n","7457     -0.314186     -0.580689     -0.066276      0.509617      0.852371  \n","7458      0.020877     -0.232491     -0.106829      0.114766      0.010555  \n","7459     -0.350397      0.389713      0.117514     -0.176062      0.473168  \n","\n","[7460 rows x 400 columns]"],"text/html":["\n","  <div id=\"df-1bd40887-ea45-41b8-8c8d-62182cfcfc4a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>coauthors_0</th>\n","      <th>coauthors_1</th>\n","      <th>coauthors_2</th>\n","      <th>coauthors_3</th>\n","      <th>coauthors_4</th>\n","      <th>coauthors_5</th>\n","      <th>coauthors_6</th>\n","      <th>coauthors_7</th>\n","      <th>coauthors_8</th>\n","      <th>coauthors_9</th>\n","      <th>...</th>\n","      <th>abstract_190</th>\n","      <th>abstract_191</th>\n","      <th>abstract_192</th>\n","      <th>abstract_193</th>\n","      <th>abstract_194</th>\n","      <th>abstract_195</th>\n","      <th>abstract_196</th>\n","      <th>abstract_197</th>\n","      <th>abstract_198</th>\n","      <th>abstract_199</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.009571</td>\n","      <td>-0.002846</td>\n","      <td>-0.008844</td>\n","      <td>-0.000511</td>\n","      <td>-0.001075</td>\n","      <td>-0.001923</td>\n","      <td>-0.006986</td>\n","      <td>0.000874</td>\n","      <td>-0.000477</td>\n","      <td>0.000430</td>\n","      <td>...</td>\n","      <td>-0.316160</td>\n","      <td>0.556565</td>\n","      <td>0.194132</td>\n","      <td>-0.410025</td>\n","      <td>-0.349819</td>\n","      <td>-0.085313</td>\n","      <td>0.577743</td>\n","      <td>0.023656</td>\n","      <td>0.123779</td>\n","      <td>0.451074</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.011007</td>\n","      <td>-0.003905</td>\n","      <td>-0.012550</td>\n","      <td>-0.000712</td>\n","      <td>-0.001495</td>\n","      <td>-0.003017</td>\n","      <td>-0.009968</td>\n","      <td>0.001208</td>\n","      <td>-0.000901</td>\n","      <td>0.000935</td>\n","      <td>...</td>\n","      <td>0.124113</td>\n","      <td>0.142072</td>\n","      <td>0.247351</td>\n","      <td>0.190889</td>\n","      <td>0.516250</td>\n","      <td>0.441111</td>\n","      <td>-0.146353</td>\n","      <td>0.278677</td>\n","      <td>-0.005393</td>\n","      <td>0.177249</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.009434</td>\n","      <td>-0.002798</td>\n","      <td>-0.008725</td>\n","      <td>-0.000478</td>\n","      <td>-0.000973</td>\n","      <td>-0.001885</td>\n","      <td>-0.006686</td>\n","      <td>0.000754</td>\n","      <td>-0.000503</td>\n","      <td>0.000484</td>\n","      <td>...</td>\n","      <td>-0.299515</td>\n","      <td>-0.038687</td>\n","      <td>-0.270053</td>\n","      <td>-0.286963</td>\n","      <td>-0.070599</td>\n","      <td>-0.218529</td>\n","      <td>-0.031311</td>\n","      <td>0.447944</td>\n","      <td>-0.078734</td>\n","      <td>0.306917</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.009921</td>\n","      <td>-0.003203</td>\n","      <td>-0.009576</td>\n","      <td>-0.000076</td>\n","      <td>-0.001061</td>\n","      <td>-0.001889</td>\n","      <td>-0.007728</td>\n","      <td>0.000643</td>\n","      <td>-0.001342</td>\n","      <td>-0.000928</td>\n","      <td>...</td>\n","      <td>0.384354</td>\n","      <td>0.188743</td>\n","      <td>0.227883</td>\n","      <td>-0.687872</td>\n","      <td>0.563455</td>\n","      <td>0.179416</td>\n","      <td>0.207539</td>\n","      <td>-0.204147</td>\n","      <td>0.209244</td>\n","      <td>-0.301667</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.010378</td>\n","      <td>-0.004540</td>\n","      <td>-0.012820</td>\n","      <td>-0.000562</td>\n","      <td>-0.001430</td>\n","      <td>-0.003136</td>\n","      <td>-0.010055</td>\n","      <td>0.001154</td>\n","      <td>0.001767</td>\n","      <td>0.001176</td>\n","      <td>...</td>\n","      <td>0.870087</td>\n","      <td>0.495401</td>\n","      <td>-0.001753</td>\n","      <td>-0.538688</td>\n","      <td>-0.053328</td>\n","      <td>-0.016859</td>\n","      <td>0.220541</td>\n","      <td>-1.012202</td>\n","      <td>-0.373231</td>\n","      <td>1.549151</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7455</th>\n","      <td>-0.009283</td>\n","      <td>-0.005068</td>\n","      <td>-0.005012</td>\n","      <td>-0.001051</td>\n","      <td>-0.002071</td>\n","      <td>-0.005167</td>\n","      <td>-0.011075</td>\n","      <td>-0.003089</td>\n","      <td>-0.000469</td>\n","      <td>0.021100</td>\n","      <td>...</td>\n","      <td>0.024630</td>\n","      <td>0.372056</td>\n","      <td>-0.389966</td>\n","      <td>0.100623</td>\n","      <td>-0.315273</td>\n","      <td>0.166802</td>\n","      <td>-0.004482</td>\n","      <td>0.113307</td>\n","      <td>0.450305</td>\n","      <td>-0.196696</td>\n","    </tr>\n","    <tr>\n","      <th>7456</th>\n","      <td>-0.009852</td>\n","      <td>-0.003023</td>\n","      <td>-0.009470</td>\n","      <td>-0.000521</td>\n","      <td>-0.001063</td>\n","      <td>-0.002067</td>\n","      <td>-0.007342</td>\n","      <td>0.000830</td>\n","      <td>-0.000558</td>\n","      <td>0.000540</td>\n","      <td>...</td>\n","      <td>0.588100</td>\n","      <td>-0.366446</td>\n","      <td>-0.406382</td>\n","      <td>-0.143317</td>\n","      <td>0.314082</td>\n","      <td>-0.302000</td>\n","      <td>-0.349476</td>\n","      <td>0.570553</td>\n","      <td>0.615917</td>\n","      <td>0.461205</td>\n","    </tr>\n","    <tr>\n","      <th>7457</th>\n","      <td>0.092097</td>\n","      <td>0.059339</td>\n","      <td>-0.050990</td>\n","      <td>0.001464</td>\n","      <td>-0.005062</td>\n","      <td>0.027925</td>\n","      <td>-0.003616</td>\n","      <td>0.025550</td>\n","      <td>-0.016458</td>\n","      <td>0.019490</td>\n","      <td>...</td>\n","      <td>1.073664</td>\n","      <td>-0.396448</td>\n","      <td>-0.107901</td>\n","      <td>1.289523</td>\n","      <td>0.272125</td>\n","      <td>-0.314186</td>\n","      <td>-0.580689</td>\n","      <td>-0.066276</td>\n","      <td>0.509617</td>\n","      <td>0.852371</td>\n","    </tr>\n","    <tr>\n","      <th>7458</th>\n","      <td>-0.010877</td>\n","      <td>-0.003379</td>\n","      <td>-0.009356</td>\n","      <td>-0.002581</td>\n","      <td>-0.002564</td>\n","      <td>-0.003929</td>\n","      <td>-0.010583</td>\n","      <td>-0.000069</td>\n","      <td>-0.000409</td>\n","      <td>-0.001764</td>\n","      <td>...</td>\n","      <td>-0.213597</td>\n","      <td>-0.007666</td>\n","      <td>0.129398</td>\n","      <td>0.164094</td>\n","      <td>-0.270876</td>\n","      <td>0.020877</td>\n","      <td>-0.232491</td>\n","      <td>-0.106829</td>\n","      <td>0.114766</td>\n","      <td>0.010555</td>\n","    </tr>\n","    <tr>\n","      <th>7459</th>\n","      <td>-0.010034</td>\n","      <td>-0.003400</td>\n","      <td>-0.010397</td>\n","      <td>0.000264</td>\n","      <td>-0.001215</td>\n","      <td>-0.001599</td>\n","      <td>-0.009451</td>\n","      <td>-0.000754</td>\n","      <td>-0.004186</td>\n","      <td>-0.007637</td>\n","      <td>...</td>\n","      <td>-0.746779</td>\n","      <td>0.302515</td>\n","      <td>0.216772</td>\n","      <td>0.040022</td>\n","      <td>-0.459893</td>\n","      <td>-0.350397</td>\n","      <td>0.389713</td>\n","      <td>0.117514</td>\n","      <td>-0.176062</td>\n","      <td>0.473168</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7460 rows × 400 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bd40887-ea45-41b8-8c8d-62182cfcfc4a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1bd40887-ea45-41b8-8c8d-62182cfcfc4a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1bd40887-ea45-41b8-8c8d-62182cfcfc4a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["df_coauthors_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"PY0o_EZ8t-Pb","executionInfo":{"status":"ok","timestamp":1664450771847,"user_tz":-600,"elapsed":28,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"66bbc418-a43c-4126-c7e3-650831291cd2"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      coauthors_0  coauthors_1  coauthors_2  coauthors_3  coauthors_4  \\\n","0       -0.009571    -0.002846    -0.008844    -0.000511    -0.001075   \n","1       -0.011007    -0.003905    -0.012550    -0.000712    -0.001495   \n","2       -0.009434    -0.002798    -0.008725    -0.000478    -0.000973   \n","3       -0.009921    -0.003203    -0.009576    -0.000076    -0.001061   \n","4       -0.010378    -0.004540    -0.012820    -0.000562    -0.001430   \n","...           ...          ...          ...          ...          ...   \n","7455    -0.009283    -0.005068    -0.005012    -0.001051    -0.002071   \n","7456    -0.009852    -0.003023    -0.009470    -0.000521    -0.001063   \n","7457     0.092097     0.059339    -0.050990     0.001464    -0.005062   \n","7458    -0.010877    -0.003379    -0.009356    -0.002581    -0.002564   \n","7459    -0.010034    -0.003400    -0.010397     0.000264    -0.001215   \n","\n","      coauthors_5  coauthors_6  coauthors_7  coauthors_8  coauthors_9  ...  \\\n","0       -0.001923    -0.006986     0.000874    -0.000477     0.000430  ...   \n","1       -0.003017    -0.009968     0.001208    -0.000901     0.000935  ...   \n","2       -0.001885    -0.006686     0.000754    -0.000503     0.000484  ...   \n","3       -0.001889    -0.007728     0.000643    -0.001342    -0.000928  ...   \n","4       -0.003136    -0.010055     0.001154     0.001767     0.001176  ...   \n","...           ...          ...          ...          ...          ...  ...   \n","7455    -0.005167    -0.011075    -0.003089    -0.000469     0.021100  ...   \n","7456    -0.002067    -0.007342     0.000830    -0.000558     0.000540  ...   \n","7457     0.027925    -0.003616     0.025550    -0.016458     0.019490  ...   \n","7458    -0.003929    -0.010583    -0.000069    -0.000409    -0.001764  ...   \n","7459    -0.001599    -0.009451    -0.000754    -0.004186    -0.007637  ...   \n","\n","      coauthors_90  coauthors_91  coauthors_92  coauthors_93  coauthors_94  \\\n","0         0.001993      0.000719      0.002881     -0.003325     -0.002331   \n","1         0.003487      0.008649      0.018916      0.003994      0.000111   \n","2         0.000878      0.000633      0.003144     -0.004248     -0.000891   \n","3        -0.002706      0.004429      0.006483     -0.008036     -0.010912   \n","4         0.038717      0.008802      0.016410     -0.024823     -0.006347   \n","...            ...           ...           ...           ...           ...   \n","7455     -0.098502     -0.012798     -0.086201      0.005014      0.003279   \n","7456      0.001284      0.000818      0.004202     -0.005537     -0.001161   \n","7457      0.005905     -0.029116      0.002259     -0.006203     -0.007285   \n","7458     -0.004989      0.068613     -0.022895      0.067553     -0.016738   \n","7459      0.007399      0.008811      0.006529     -0.020755      0.015057   \n","\n","      coauthors_95  coauthors_96  coauthors_97  coauthors_98  coauthors_99  \n","0         0.000460     -0.003749     -0.001203      0.000053     -0.001692  \n","1         0.012183     -0.006647     -0.004866     -0.010021     -0.009317  \n","2         0.001308     -0.004126     -0.001651     -0.000352     -0.001305  \n","3         0.010227     -0.005913      0.001391      0.002756     -0.001816  \n","4         0.009623     -0.013238      0.009141      0.013797      0.009710  \n","...            ...           ...           ...           ...           ...  \n","7455      0.018240      0.090990      0.008121     -0.014214     -0.080952  \n","7456      0.001758     -0.005543     -0.002195     -0.000508     -0.001807  \n","7457     -0.001115      0.027806     -0.014079      0.000511      0.004656  \n","7458      0.180067      0.036072     -0.223458      0.000431      0.088796  \n","7459     -0.010597      0.006041      0.016444     -0.009241      0.014516  \n","\n","[7460 rows x 100 columns]"],"text/html":["\n","  <div id=\"df-4216893c-074e-4b3e-b86b-fb797d93c313\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>coauthors_0</th>\n","      <th>coauthors_1</th>\n","      <th>coauthors_2</th>\n","      <th>coauthors_3</th>\n","      <th>coauthors_4</th>\n","      <th>coauthors_5</th>\n","      <th>coauthors_6</th>\n","      <th>coauthors_7</th>\n","      <th>coauthors_8</th>\n","      <th>coauthors_9</th>\n","      <th>...</th>\n","      <th>coauthors_90</th>\n","      <th>coauthors_91</th>\n","      <th>coauthors_92</th>\n","      <th>coauthors_93</th>\n","      <th>coauthors_94</th>\n","      <th>coauthors_95</th>\n","      <th>coauthors_96</th>\n","      <th>coauthors_97</th>\n","      <th>coauthors_98</th>\n","      <th>coauthors_99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.009571</td>\n","      <td>-0.002846</td>\n","      <td>-0.008844</td>\n","      <td>-0.000511</td>\n","      <td>-0.001075</td>\n","      <td>-0.001923</td>\n","      <td>-0.006986</td>\n","      <td>0.000874</td>\n","      <td>-0.000477</td>\n","      <td>0.000430</td>\n","      <td>...</td>\n","      <td>0.001993</td>\n","      <td>0.000719</td>\n","      <td>0.002881</td>\n","      <td>-0.003325</td>\n","      <td>-0.002331</td>\n","      <td>0.000460</td>\n","      <td>-0.003749</td>\n","      <td>-0.001203</td>\n","      <td>0.000053</td>\n","      <td>-0.001692</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.011007</td>\n","      <td>-0.003905</td>\n","      <td>-0.012550</td>\n","      <td>-0.000712</td>\n","      <td>-0.001495</td>\n","      <td>-0.003017</td>\n","      <td>-0.009968</td>\n","      <td>0.001208</td>\n","      <td>-0.000901</td>\n","      <td>0.000935</td>\n","      <td>...</td>\n","      <td>0.003487</td>\n","      <td>0.008649</td>\n","      <td>0.018916</td>\n","      <td>0.003994</td>\n","      <td>0.000111</td>\n","      <td>0.012183</td>\n","      <td>-0.006647</td>\n","      <td>-0.004866</td>\n","      <td>-0.010021</td>\n","      <td>-0.009317</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.009434</td>\n","      <td>-0.002798</td>\n","      <td>-0.008725</td>\n","      <td>-0.000478</td>\n","      <td>-0.000973</td>\n","      <td>-0.001885</td>\n","      <td>-0.006686</td>\n","      <td>0.000754</td>\n","      <td>-0.000503</td>\n","      <td>0.000484</td>\n","      <td>...</td>\n","      <td>0.000878</td>\n","      <td>0.000633</td>\n","      <td>0.003144</td>\n","      <td>-0.004248</td>\n","      <td>-0.000891</td>\n","      <td>0.001308</td>\n","      <td>-0.004126</td>\n","      <td>-0.001651</td>\n","      <td>-0.000352</td>\n","      <td>-0.001305</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.009921</td>\n","      <td>-0.003203</td>\n","      <td>-0.009576</td>\n","      <td>-0.000076</td>\n","      <td>-0.001061</td>\n","      <td>-0.001889</td>\n","      <td>-0.007728</td>\n","      <td>0.000643</td>\n","      <td>-0.001342</td>\n","      <td>-0.000928</td>\n","      <td>...</td>\n","      <td>-0.002706</td>\n","      <td>0.004429</td>\n","      <td>0.006483</td>\n","      <td>-0.008036</td>\n","      <td>-0.010912</td>\n","      <td>0.010227</td>\n","      <td>-0.005913</td>\n","      <td>0.001391</td>\n","      <td>0.002756</td>\n","      <td>-0.001816</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.010378</td>\n","      <td>-0.004540</td>\n","      <td>-0.012820</td>\n","      <td>-0.000562</td>\n","      <td>-0.001430</td>\n","      <td>-0.003136</td>\n","      <td>-0.010055</td>\n","      <td>0.001154</td>\n","      <td>0.001767</td>\n","      <td>0.001176</td>\n","      <td>...</td>\n","      <td>0.038717</td>\n","      <td>0.008802</td>\n","      <td>0.016410</td>\n","      <td>-0.024823</td>\n","      <td>-0.006347</td>\n","      <td>0.009623</td>\n","      <td>-0.013238</td>\n","      <td>0.009141</td>\n","      <td>0.013797</td>\n","      <td>0.009710</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7455</th>\n","      <td>-0.009283</td>\n","      <td>-0.005068</td>\n","      <td>-0.005012</td>\n","      <td>-0.001051</td>\n","      <td>-0.002071</td>\n","      <td>-0.005167</td>\n","      <td>-0.011075</td>\n","      <td>-0.003089</td>\n","      <td>-0.000469</td>\n","      <td>0.021100</td>\n","      <td>...</td>\n","      <td>-0.098502</td>\n","      <td>-0.012798</td>\n","      <td>-0.086201</td>\n","      <td>0.005014</td>\n","      <td>0.003279</td>\n","      <td>0.018240</td>\n","      <td>0.090990</td>\n","      <td>0.008121</td>\n","      <td>-0.014214</td>\n","      <td>-0.080952</td>\n","    </tr>\n","    <tr>\n","      <th>7456</th>\n","      <td>-0.009852</td>\n","      <td>-0.003023</td>\n","      <td>-0.009470</td>\n","      <td>-0.000521</td>\n","      <td>-0.001063</td>\n","      <td>-0.002067</td>\n","      <td>-0.007342</td>\n","      <td>0.000830</td>\n","      <td>-0.000558</td>\n","      <td>0.000540</td>\n","      <td>...</td>\n","      <td>0.001284</td>\n","      <td>0.000818</td>\n","      <td>0.004202</td>\n","      <td>-0.005537</td>\n","      <td>-0.001161</td>\n","      <td>0.001758</td>\n","      <td>-0.005543</td>\n","      <td>-0.002195</td>\n","      <td>-0.000508</td>\n","      <td>-0.001807</td>\n","    </tr>\n","    <tr>\n","      <th>7457</th>\n","      <td>0.092097</td>\n","      <td>0.059339</td>\n","      <td>-0.050990</td>\n","      <td>0.001464</td>\n","      <td>-0.005062</td>\n","      <td>0.027925</td>\n","      <td>-0.003616</td>\n","      <td>0.025550</td>\n","      <td>-0.016458</td>\n","      <td>0.019490</td>\n","      <td>...</td>\n","      <td>0.005905</td>\n","      <td>-0.029116</td>\n","      <td>0.002259</td>\n","      <td>-0.006203</td>\n","      <td>-0.007285</td>\n","      <td>-0.001115</td>\n","      <td>0.027806</td>\n","      <td>-0.014079</td>\n","      <td>0.000511</td>\n","      <td>0.004656</td>\n","    </tr>\n","    <tr>\n","      <th>7458</th>\n","      <td>-0.010877</td>\n","      <td>-0.003379</td>\n","      <td>-0.009356</td>\n","      <td>-0.002581</td>\n","      <td>-0.002564</td>\n","      <td>-0.003929</td>\n","      <td>-0.010583</td>\n","      <td>-0.000069</td>\n","      <td>-0.000409</td>\n","      <td>-0.001764</td>\n","      <td>...</td>\n","      <td>-0.004989</td>\n","      <td>0.068613</td>\n","      <td>-0.022895</td>\n","      <td>0.067553</td>\n","      <td>-0.016738</td>\n","      <td>0.180067</td>\n","      <td>0.036072</td>\n","      <td>-0.223458</td>\n","      <td>0.000431</td>\n","      <td>0.088796</td>\n","    </tr>\n","    <tr>\n","      <th>7459</th>\n","      <td>-0.010034</td>\n","      <td>-0.003400</td>\n","      <td>-0.010397</td>\n","      <td>0.000264</td>\n","      <td>-0.001215</td>\n","      <td>-0.001599</td>\n","      <td>-0.009451</td>\n","      <td>-0.000754</td>\n","      <td>-0.004186</td>\n","      <td>-0.007637</td>\n","      <td>...</td>\n","      <td>0.007399</td>\n","      <td>0.008811</td>\n","      <td>0.006529</td>\n","      <td>-0.020755</td>\n","      <td>0.015057</td>\n","      <td>-0.010597</td>\n","      <td>0.006041</td>\n","      <td>0.016444</td>\n","      <td>-0.009241</td>\n","      <td>0.014516</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7460 rows × 100 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4216893c-074e-4b3e-b86b-fb797d93c313')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4216893c-074e-4b3e-b86b-fb797d93c313 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4216893c-074e-4b3e-b86b-fb797d93c313');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["df_title_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"qnYgZL01t-Ws","executionInfo":{"status":"ok","timestamp":1664450771847,"user_tz":-600,"elapsed":27,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"832bf4fc-00e3-4a94-8160-af49cea1413a"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       title_0   title_1   title_2   title_3   title_4   title_5   title_6  \\\n","0    -0.104390 -0.899345 -0.434115  0.014167 -0.615432 -0.230758  0.037018   \n","1    -0.061744  0.965644  1.560803  0.042176 -0.889819 -0.223741  0.303561   \n","2    -0.715197 -0.552108  0.003134  1.098545  1.593943 -0.659770  0.407286   \n","3    -0.980859  0.771059 -1.256239 -0.710768  0.153766  0.275984  0.450083   \n","4     0.419577  2.150678  1.427501  1.704239 -1.918350 -0.691028  0.416509   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","7455 -0.952211 -0.586320 -0.080592  0.052563 -0.078157 -0.272398  0.347230   \n","7456 -0.528040 -0.178056  0.875995 -0.506144  0.287300  1.417883  0.656316   \n","7457 -0.874029 -0.052301  0.036527  0.618481 -0.904660 -0.119751 -0.011450   \n","7458  0.145490 -0.656746 -0.272504  0.719806  1.256791 -0.224620  0.453831   \n","7459 -0.759908  1.350924 -1.576675 -0.567383  1.186212 -0.730666 -0.454110   \n","\n","       title_7   title_8   title_9  ...  title_90  title_91  title_92  \\\n","0     0.429025 -0.064514  0.910843  ... -0.007803  0.216295 -0.038014   \n","1    -0.755781 -0.543063 -0.987239  ...  0.000317  0.034429  0.035656   \n","2    -0.149940  0.651641 -0.007559  ...  0.010791  0.193201 -0.302337   \n","3    -0.237215 -0.678538 -0.643243  ...  0.372838 -0.568613 -0.053789   \n","4     0.059435  0.840164  0.076216  ... -0.049131  0.548976  0.360282   \n","...        ...       ...       ...  ...       ...       ...       ...   \n","7455  0.132454 -0.063954  0.418303  ...  0.049821  0.042997  0.149338   \n","7456 -1.044156  1.382964  0.663548  ... -0.139289  0.145387 -0.303620   \n","7457 -0.180017 -0.040005 -0.597550  ... -0.043845  0.061248  0.168951   \n","7458 -0.242561  0.468189 -0.154747  ... -0.070102 -0.036094  0.051193   \n","7459  0.306393  0.654263 -0.040350  ... -0.221605  0.133163 -0.045068   \n","\n","      title_93  title_94  title_95  title_96  title_97  title_98  title_99  \n","0    -0.054866 -0.202865  0.034769 -0.033622  0.136720  0.134015 -0.048192  \n","1     0.154158 -0.024986 -0.144253  0.078227  0.176758  0.099190  0.257979  \n","2     0.069112  0.265473  0.052770 -0.014499  0.155522 -0.192287 -0.184186  \n","3    -0.186024 -0.470164 -0.446689  0.156469 -0.137272 -0.110689  0.130181  \n","4    -0.155778 -0.228214 -0.087469  0.039023 -0.264784 -0.175169 -0.111621  \n","...        ...       ...       ...       ...       ...       ...       ...  \n","7455 -0.255395  0.079646  0.049009 -0.014125 -0.123616 -0.038850 -0.096674  \n","7456 -0.313543 -0.021538  0.204740 -0.223923 -0.063029 -0.189510 -0.566919  \n","7457  0.015619  0.153930 -0.030494 -0.223879  0.186967  0.052016  0.121839  \n","7458  0.121419 -0.196160 -0.080483  0.136935  0.059110  0.301246  0.064327  \n","7459 -0.031130  0.060480 -0.069911  0.050341 -0.105221 -0.023257 -0.166182  \n","\n","[7460 rows x 100 columns]"],"text/html":["\n","  <div id=\"df-23b77604-52c3-49f8-b92b-63f3099e1a04\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title_0</th>\n","      <th>title_1</th>\n","      <th>title_2</th>\n","      <th>title_3</th>\n","      <th>title_4</th>\n","      <th>title_5</th>\n","      <th>title_6</th>\n","      <th>title_7</th>\n","      <th>title_8</th>\n","      <th>title_9</th>\n","      <th>...</th>\n","      <th>title_90</th>\n","      <th>title_91</th>\n","      <th>title_92</th>\n","      <th>title_93</th>\n","      <th>title_94</th>\n","      <th>title_95</th>\n","      <th>title_96</th>\n","      <th>title_97</th>\n","      <th>title_98</th>\n","      <th>title_99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.104390</td>\n","      <td>-0.899345</td>\n","      <td>-0.434115</td>\n","      <td>0.014167</td>\n","      <td>-0.615432</td>\n","      <td>-0.230758</td>\n","      <td>0.037018</td>\n","      <td>0.429025</td>\n","      <td>-0.064514</td>\n","      <td>0.910843</td>\n","      <td>...</td>\n","      <td>-0.007803</td>\n","      <td>0.216295</td>\n","      <td>-0.038014</td>\n","      <td>-0.054866</td>\n","      <td>-0.202865</td>\n","      <td>0.034769</td>\n","      <td>-0.033622</td>\n","      <td>0.136720</td>\n","      <td>0.134015</td>\n","      <td>-0.048192</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.061744</td>\n","      <td>0.965644</td>\n","      <td>1.560803</td>\n","      <td>0.042176</td>\n","      <td>-0.889819</td>\n","      <td>-0.223741</td>\n","      <td>0.303561</td>\n","      <td>-0.755781</td>\n","      <td>-0.543063</td>\n","      <td>-0.987239</td>\n","      <td>...</td>\n","      <td>0.000317</td>\n","      <td>0.034429</td>\n","      <td>0.035656</td>\n","      <td>0.154158</td>\n","      <td>-0.024986</td>\n","      <td>-0.144253</td>\n","      <td>0.078227</td>\n","      <td>0.176758</td>\n","      <td>0.099190</td>\n","      <td>0.257979</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.715197</td>\n","      <td>-0.552108</td>\n","      <td>0.003134</td>\n","      <td>1.098545</td>\n","      <td>1.593943</td>\n","      <td>-0.659770</td>\n","      <td>0.407286</td>\n","      <td>-0.149940</td>\n","      <td>0.651641</td>\n","      <td>-0.007559</td>\n","      <td>...</td>\n","      <td>0.010791</td>\n","      <td>0.193201</td>\n","      <td>-0.302337</td>\n","      <td>0.069112</td>\n","      <td>0.265473</td>\n","      <td>0.052770</td>\n","      <td>-0.014499</td>\n","      <td>0.155522</td>\n","      <td>-0.192287</td>\n","      <td>-0.184186</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.980859</td>\n","      <td>0.771059</td>\n","      <td>-1.256239</td>\n","      <td>-0.710768</td>\n","      <td>0.153766</td>\n","      <td>0.275984</td>\n","      <td>0.450083</td>\n","      <td>-0.237215</td>\n","      <td>-0.678538</td>\n","      <td>-0.643243</td>\n","      <td>...</td>\n","      <td>0.372838</td>\n","      <td>-0.568613</td>\n","      <td>-0.053789</td>\n","      <td>-0.186024</td>\n","      <td>-0.470164</td>\n","      <td>-0.446689</td>\n","      <td>0.156469</td>\n","      <td>-0.137272</td>\n","      <td>-0.110689</td>\n","      <td>0.130181</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.419577</td>\n","      <td>2.150678</td>\n","      <td>1.427501</td>\n","      <td>1.704239</td>\n","      <td>-1.918350</td>\n","      <td>-0.691028</td>\n","      <td>0.416509</td>\n","      <td>0.059435</td>\n","      <td>0.840164</td>\n","      <td>0.076216</td>\n","      <td>...</td>\n","      <td>-0.049131</td>\n","      <td>0.548976</td>\n","      <td>0.360282</td>\n","      <td>-0.155778</td>\n","      <td>-0.228214</td>\n","      <td>-0.087469</td>\n","      <td>0.039023</td>\n","      <td>-0.264784</td>\n","      <td>-0.175169</td>\n","      <td>-0.111621</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7455</th>\n","      <td>-0.952211</td>\n","      <td>-0.586320</td>\n","      <td>-0.080592</td>\n","      <td>0.052563</td>\n","      <td>-0.078157</td>\n","      <td>-0.272398</td>\n","      <td>0.347230</td>\n","      <td>0.132454</td>\n","      <td>-0.063954</td>\n","      <td>0.418303</td>\n","      <td>...</td>\n","      <td>0.049821</td>\n","      <td>0.042997</td>\n","      <td>0.149338</td>\n","      <td>-0.255395</td>\n","      <td>0.079646</td>\n","      <td>0.049009</td>\n","      <td>-0.014125</td>\n","      <td>-0.123616</td>\n","      <td>-0.038850</td>\n","      <td>-0.096674</td>\n","    </tr>\n","    <tr>\n","      <th>7456</th>\n","      <td>-0.528040</td>\n","      <td>-0.178056</td>\n","      <td>0.875995</td>\n","      <td>-0.506144</td>\n","      <td>0.287300</td>\n","      <td>1.417883</td>\n","      <td>0.656316</td>\n","      <td>-1.044156</td>\n","      <td>1.382964</td>\n","      <td>0.663548</td>\n","      <td>...</td>\n","      <td>-0.139289</td>\n","      <td>0.145387</td>\n","      <td>-0.303620</td>\n","      <td>-0.313543</td>\n","      <td>-0.021538</td>\n","      <td>0.204740</td>\n","      <td>-0.223923</td>\n","      <td>-0.063029</td>\n","      <td>-0.189510</td>\n","      <td>-0.566919</td>\n","    </tr>\n","    <tr>\n","      <th>7457</th>\n","      <td>-0.874029</td>\n","      <td>-0.052301</td>\n","      <td>0.036527</td>\n","      <td>0.618481</td>\n","      <td>-0.904660</td>\n","      <td>-0.119751</td>\n","      <td>-0.011450</td>\n","      <td>-0.180017</td>\n","      <td>-0.040005</td>\n","      <td>-0.597550</td>\n","      <td>...</td>\n","      <td>-0.043845</td>\n","      <td>0.061248</td>\n","      <td>0.168951</td>\n","      <td>0.015619</td>\n","      <td>0.153930</td>\n","      <td>-0.030494</td>\n","      <td>-0.223879</td>\n","      <td>0.186967</td>\n","      <td>0.052016</td>\n","      <td>0.121839</td>\n","    </tr>\n","    <tr>\n","      <th>7458</th>\n","      <td>0.145490</td>\n","      <td>-0.656746</td>\n","      <td>-0.272504</td>\n","      <td>0.719806</td>\n","      <td>1.256791</td>\n","      <td>-0.224620</td>\n","      <td>0.453831</td>\n","      <td>-0.242561</td>\n","      <td>0.468189</td>\n","      <td>-0.154747</td>\n","      <td>...</td>\n","      <td>-0.070102</td>\n","      <td>-0.036094</td>\n","      <td>0.051193</td>\n","      <td>0.121419</td>\n","      <td>-0.196160</td>\n","      <td>-0.080483</td>\n","      <td>0.136935</td>\n","      <td>0.059110</td>\n","      <td>0.301246</td>\n","      <td>0.064327</td>\n","    </tr>\n","    <tr>\n","      <th>7459</th>\n","      <td>-0.759908</td>\n","      <td>1.350924</td>\n","      <td>-1.576675</td>\n","      <td>-0.567383</td>\n","      <td>1.186212</td>\n","      <td>-0.730666</td>\n","      <td>-0.454110</td>\n","      <td>0.306393</td>\n","      <td>0.654263</td>\n","      <td>-0.040350</td>\n","      <td>...</td>\n","      <td>-0.221605</td>\n","      <td>0.133163</td>\n","      <td>-0.045068</td>\n","      <td>-0.031130</td>\n","      <td>0.060480</td>\n","      <td>-0.069911</td>\n","      <td>0.050341</td>\n","      <td>-0.105221</td>\n","      <td>-0.023257</td>\n","      <td>-0.166182</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7460 rows × 100 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23b77604-52c3-49f8-b92b-63f3099e1a04')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-23b77604-52c3-49f8-b92b-63f3099e1a04 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-23b77604-52c3-49f8-b92b-63f3099e1a04');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["df_abstract_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"ly80SWBR3UYn","executionInfo":{"status":"ok","timestamp":1664450771848,"user_tz":-600,"elapsed":27,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"075c33af-e019-4acb-a0c0-e6c673720765"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      abstract_0  abstract_1  abstract_2  abstract_3  abstract_4  abstract_5  \\\n","0      -6.532645   -1.783645   -2.704608    1.527618   -2.006903    1.253318   \n","1      -3.997916   -4.132037    1.799356   -0.724305    2.077230    0.697334   \n","2      -4.944162    3.203725   -1.250631    0.836960   -0.399517    0.455560   \n","3      -4.402092   -1.638486   -2.341381    1.216474    3.082062    0.124830   \n","4      -0.164966    0.380490    7.773817    1.615499   -3.934496   -3.411055   \n","...          ...         ...         ...         ...         ...         ...   \n","7455   -3.844675   -2.737017   -2.130538   -1.443552    2.562788    0.383540   \n","7456   -0.438266   -3.292679   -3.145180   -2.215988   -1.398203   -0.758516   \n","7457   -0.834171    3.179941   -1.953299   -2.068563    4.067145    0.158689   \n","7458   -8.079442    2.027224   -0.992181    0.419949   -0.421532   -1.627133   \n","7459    1.071772   -5.880975    0.423924   -2.353955    3.251038   -2.914757   \n","\n","      abstract_6  abstract_7  abstract_8  abstract_9  ...  abstract_190  \\\n","0       1.009644   -2.113763    2.927393    0.692333  ...     -0.316160   \n","1       2.564390    0.499511    0.052518    0.757283  ...      0.124113   \n","2       1.308898   -1.376809   -1.437708   -0.114222  ...     -0.299515   \n","3       0.445660   -0.211135   -0.321364    2.558900  ...      0.384354   \n","4       0.852442    0.542791   -0.663889   -1.561843  ...      0.870087   \n","...          ...         ...         ...         ...  ...           ...   \n","7455    0.331700    0.347616    0.498375   -0.339795  ...      0.024630   \n","7456    0.452337   -1.710440   -1.307031    0.779634  ...      0.588100   \n","7457   -0.492177    1.417444   -0.492645   -1.177257  ...      1.073664   \n","7458    0.875830   -0.211482    0.129860    1.273333  ...     -0.213597   \n","7459    2.035162   -1.524474   -0.385873   -0.958031  ...     -0.746779   \n","\n","      abstract_191  abstract_192  abstract_193  abstract_194  abstract_195  \\\n","0         0.556565      0.194132     -0.410025     -0.349819     -0.085313   \n","1         0.142072      0.247351      0.190889      0.516250      0.441111   \n","2        -0.038687     -0.270053     -0.286963     -0.070599     -0.218529   \n","3         0.188743      0.227883     -0.687872      0.563455      0.179416   \n","4         0.495401     -0.001753     -0.538688     -0.053328     -0.016859   \n","...            ...           ...           ...           ...           ...   \n","7455      0.372056     -0.389966      0.100623     -0.315273      0.166802   \n","7456     -0.366446     -0.406382     -0.143317      0.314082     -0.302000   \n","7457     -0.396448     -0.107901      1.289523      0.272125     -0.314186   \n","7458     -0.007666      0.129398      0.164094     -0.270876      0.020877   \n","7459      0.302515      0.216772      0.040022     -0.459893     -0.350397   \n","\n","      abstract_196  abstract_197  abstract_198  abstract_199  \n","0         0.577743      0.023656      0.123779      0.451074  \n","1        -0.146353      0.278677     -0.005393      0.177249  \n","2        -0.031311      0.447944     -0.078734      0.306917  \n","3         0.207539     -0.204147      0.209244     -0.301667  \n","4         0.220541     -1.012202     -0.373231      1.549151  \n","...            ...           ...           ...           ...  \n","7455     -0.004482      0.113307      0.450305     -0.196696  \n","7456     -0.349476      0.570553      0.615917      0.461205  \n","7457     -0.580689     -0.066276      0.509617      0.852371  \n","7458     -0.232491     -0.106829      0.114766      0.010555  \n","7459      0.389713      0.117514     -0.176062      0.473168  \n","\n","[7460 rows x 200 columns]"],"text/html":["\n","  <div id=\"df-67d6b3ce-8c5b-4719-81ca-006b684c7c2c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>abstract_0</th>\n","      <th>abstract_1</th>\n","      <th>abstract_2</th>\n","      <th>abstract_3</th>\n","      <th>abstract_4</th>\n","      <th>abstract_5</th>\n","      <th>abstract_6</th>\n","      <th>abstract_7</th>\n","      <th>abstract_8</th>\n","      <th>abstract_9</th>\n","      <th>...</th>\n","      <th>abstract_190</th>\n","      <th>abstract_191</th>\n","      <th>abstract_192</th>\n","      <th>abstract_193</th>\n","      <th>abstract_194</th>\n","      <th>abstract_195</th>\n","      <th>abstract_196</th>\n","      <th>abstract_197</th>\n","      <th>abstract_198</th>\n","      <th>abstract_199</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-6.532645</td>\n","      <td>-1.783645</td>\n","      <td>-2.704608</td>\n","      <td>1.527618</td>\n","      <td>-2.006903</td>\n","      <td>1.253318</td>\n","      <td>1.009644</td>\n","      <td>-2.113763</td>\n","      <td>2.927393</td>\n","      <td>0.692333</td>\n","      <td>...</td>\n","      <td>-0.316160</td>\n","      <td>0.556565</td>\n","      <td>0.194132</td>\n","      <td>-0.410025</td>\n","      <td>-0.349819</td>\n","      <td>-0.085313</td>\n","      <td>0.577743</td>\n","      <td>0.023656</td>\n","      <td>0.123779</td>\n","      <td>0.451074</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-3.997916</td>\n","      <td>-4.132037</td>\n","      <td>1.799356</td>\n","      <td>-0.724305</td>\n","      <td>2.077230</td>\n","      <td>0.697334</td>\n","      <td>2.564390</td>\n","      <td>0.499511</td>\n","      <td>0.052518</td>\n","      <td>0.757283</td>\n","      <td>...</td>\n","      <td>0.124113</td>\n","      <td>0.142072</td>\n","      <td>0.247351</td>\n","      <td>0.190889</td>\n","      <td>0.516250</td>\n","      <td>0.441111</td>\n","      <td>-0.146353</td>\n","      <td>0.278677</td>\n","      <td>-0.005393</td>\n","      <td>0.177249</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-4.944162</td>\n","      <td>3.203725</td>\n","      <td>-1.250631</td>\n","      <td>0.836960</td>\n","      <td>-0.399517</td>\n","      <td>0.455560</td>\n","      <td>1.308898</td>\n","      <td>-1.376809</td>\n","      <td>-1.437708</td>\n","      <td>-0.114222</td>\n","      <td>...</td>\n","      <td>-0.299515</td>\n","      <td>-0.038687</td>\n","      <td>-0.270053</td>\n","      <td>-0.286963</td>\n","      <td>-0.070599</td>\n","      <td>-0.218529</td>\n","      <td>-0.031311</td>\n","      <td>0.447944</td>\n","      <td>-0.078734</td>\n","      <td>0.306917</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-4.402092</td>\n","      <td>-1.638486</td>\n","      <td>-2.341381</td>\n","      <td>1.216474</td>\n","      <td>3.082062</td>\n","      <td>0.124830</td>\n","      <td>0.445660</td>\n","      <td>-0.211135</td>\n","      <td>-0.321364</td>\n","      <td>2.558900</td>\n","      <td>...</td>\n","      <td>0.384354</td>\n","      <td>0.188743</td>\n","      <td>0.227883</td>\n","      <td>-0.687872</td>\n","      <td>0.563455</td>\n","      <td>0.179416</td>\n","      <td>0.207539</td>\n","      <td>-0.204147</td>\n","      <td>0.209244</td>\n","      <td>-0.301667</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.164966</td>\n","      <td>0.380490</td>\n","      <td>7.773817</td>\n","      <td>1.615499</td>\n","      <td>-3.934496</td>\n","      <td>-3.411055</td>\n","      <td>0.852442</td>\n","      <td>0.542791</td>\n","      <td>-0.663889</td>\n","      <td>-1.561843</td>\n","      <td>...</td>\n","      <td>0.870087</td>\n","      <td>0.495401</td>\n","      <td>-0.001753</td>\n","      <td>-0.538688</td>\n","      <td>-0.053328</td>\n","      <td>-0.016859</td>\n","      <td>0.220541</td>\n","      <td>-1.012202</td>\n","      <td>-0.373231</td>\n","      <td>1.549151</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7455</th>\n","      <td>-3.844675</td>\n","      <td>-2.737017</td>\n","      <td>-2.130538</td>\n","      <td>-1.443552</td>\n","      <td>2.562788</td>\n","      <td>0.383540</td>\n","      <td>0.331700</td>\n","      <td>0.347616</td>\n","      <td>0.498375</td>\n","      <td>-0.339795</td>\n","      <td>...</td>\n","      <td>0.024630</td>\n","      <td>0.372056</td>\n","      <td>-0.389966</td>\n","      <td>0.100623</td>\n","      <td>-0.315273</td>\n","      <td>0.166802</td>\n","      <td>-0.004482</td>\n","      <td>0.113307</td>\n","      <td>0.450305</td>\n","      <td>-0.196696</td>\n","    </tr>\n","    <tr>\n","      <th>7456</th>\n","      <td>-0.438266</td>\n","      <td>-3.292679</td>\n","      <td>-3.145180</td>\n","      <td>-2.215988</td>\n","      <td>-1.398203</td>\n","      <td>-0.758516</td>\n","      <td>0.452337</td>\n","      <td>-1.710440</td>\n","      <td>-1.307031</td>\n","      <td>0.779634</td>\n","      <td>...</td>\n","      <td>0.588100</td>\n","      <td>-0.366446</td>\n","      <td>-0.406382</td>\n","      <td>-0.143317</td>\n","      <td>0.314082</td>\n","      <td>-0.302000</td>\n","      <td>-0.349476</td>\n","      <td>0.570553</td>\n","      <td>0.615917</td>\n","      <td>0.461205</td>\n","    </tr>\n","    <tr>\n","      <th>7457</th>\n","      <td>-0.834171</td>\n","      <td>3.179941</td>\n","      <td>-1.953299</td>\n","      <td>-2.068563</td>\n","      <td>4.067145</td>\n","      <td>0.158689</td>\n","      <td>-0.492177</td>\n","      <td>1.417444</td>\n","      <td>-0.492645</td>\n","      <td>-1.177257</td>\n","      <td>...</td>\n","      <td>1.073664</td>\n","      <td>-0.396448</td>\n","      <td>-0.107901</td>\n","      <td>1.289523</td>\n","      <td>0.272125</td>\n","      <td>-0.314186</td>\n","      <td>-0.580689</td>\n","      <td>-0.066276</td>\n","      <td>0.509617</td>\n","      <td>0.852371</td>\n","    </tr>\n","    <tr>\n","      <th>7458</th>\n","      <td>-8.079442</td>\n","      <td>2.027224</td>\n","      <td>-0.992181</td>\n","      <td>0.419949</td>\n","      <td>-0.421532</td>\n","      <td>-1.627133</td>\n","      <td>0.875830</td>\n","      <td>-0.211482</td>\n","      <td>0.129860</td>\n","      <td>1.273333</td>\n","      <td>...</td>\n","      <td>-0.213597</td>\n","      <td>-0.007666</td>\n","      <td>0.129398</td>\n","      <td>0.164094</td>\n","      <td>-0.270876</td>\n","      <td>0.020877</td>\n","      <td>-0.232491</td>\n","      <td>-0.106829</td>\n","      <td>0.114766</td>\n","      <td>0.010555</td>\n","    </tr>\n","    <tr>\n","      <th>7459</th>\n","      <td>1.071772</td>\n","      <td>-5.880975</td>\n","      <td>0.423924</td>\n","      <td>-2.353955</td>\n","      <td>3.251038</td>\n","      <td>-2.914757</td>\n","      <td>2.035162</td>\n","      <td>-1.524474</td>\n","      <td>-0.385873</td>\n","      <td>-0.958031</td>\n","      <td>...</td>\n","      <td>-0.746779</td>\n","      <td>0.302515</td>\n","      <td>0.216772</td>\n","      <td>0.040022</td>\n","      <td>-0.459893</td>\n","      <td>-0.350397</td>\n","      <td>0.389713</td>\n","      <td>0.117514</td>\n","      <td>-0.176062</td>\n","      <td>0.473168</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7460 rows × 200 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67d6b3ce-8c5b-4719-81ca-006b684c7c2c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-67d6b3ce-8c5b-4719-81ca-006b684c7c2c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-67d6b3ce-8c5b-4719-81ca-006b684c7c2c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["df_merge_coauthors_sentences.fillna(0,inplace =True)\n","df_coauthors_features.fillna(0,inplace =True)"],"metadata":{"id":"FOS9zaUy66u4","executionInfo":{"status":"ok","timestamp":1664450784431,"user_tz":-600,"elapsed":327,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["X_train,X_test,y_train,y_test = train_test_split(df_merge_coauthors_sentences,ohe_prolific_labels,test_size=0.1,random_state=90051)"],"metadata":{"id":"WjRbVY_C66wO","executionInfo":{"status":"ok","timestamp":1664451026905,"user_tz":-600,"elapsed":394,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}}},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":["## classifierchain model (无深度学习目前最好的model) Logistic Regression"],"metadata":{"id":"c08IV6f5Scod"}},{"cell_type":"code","source":["base_lr = LogisticRegression(solver='liblinear', random_state=0,max_iter = 200)\n","chain = ClassifierChain(base_lr, order='random', random_state=0)\n","# scaler = preprocessing.StandardScaler().fit(X_train)\n","# X_scaled_train = scaler.transform(X_train)\n","# X_scaled_test= scaler.transform(X_test)\n","chain.fit(X_train, y_train)\n","predictions = chain.predict(X_test)\n","f1_score(y_test, predictions, average=None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWa2I13cvvgq","executionInfo":{"status":"ok","timestamp":1664450939887,"user_tz":-600,"elapsed":147888,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"e8baffd8-d26f-4a6f-b00b-990225832f89"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.51612903, 0.5       , 0.25      , 0.33333333, 0.46153846,\n","       0.16666667, 0.23076923, 0.58823529, 0.25      , 0.        ,\n","       0.07692308, 0.33333333, 0.21052632, 0.22222222, 0.25      ,\n","       0.55172414, 0.26086957, 0.33333333, 0.5       , 0.5       ,\n","       0.        , 0.57142857, 0.2       , 0.26666667, 0.13333333,\n","       0.35294118, 0.48484848, 0.13333333, 0.2       , 0.22222222,\n","       0.        , 0.4       , 0.34482759, 0.85714286, 0.        ,\n","       0.15384615, 0.        , 0.4       , 0.34782609, 0.28571429,\n","       0.30769231, 0.18181818, 0.        , 0.5       , 0.57142857,\n","       0.71428571, 0.42857143, 0.62068966, 0.        , 0.28571429,\n","       0.        , 0.4       , 0.        , 0.08      , 0.2       ,\n","       0.6       , 0.25      , 0.26666667, 0.18181818, 0.60869565,\n","       0.        , 0.66666667, 0.        , 0.4       , 0.16666667,\n","       0.11111111, 0.57142857, 0.15384615, 0.28571429, 0.28571429,\n","       0.55555556, 0.25      , 0.26666667, 0.28571429, 0.45454545,\n","       0.42857143, 0.25      , 0.13333333, 0.66666667, 0.33333333,\n","       0.        , 0.        , 0.26666667, 0.28571429, 0.11764706,\n","       0.66666667, 0.33333333, 0.14285714, 0.        , 0.        ,\n","       0.72727273, 0.33333333, 0.53333333, 0.4       , 0.22222222,\n","       0.13333333, 0.        , 0.36363636, 0.2       , 0.        ])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["f1_score(y_test, predictions, average='samples')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqNFPmMtKt2k","executionInfo":{"status":"ok","timestamp":1664450980270,"user_tz":-600,"elapsed":366,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"b0b8d2ab-0efc-4574-941d-a355826e3b00"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.24616775836614976"]},"metadata":{},"execution_count":61}]},{"cell_type":"markdown","source":["## MLP"],"metadata":{"id":"qVr7Nla1U--R"}},{"cell_type":"code","source":["# scaler = preprocessing.StandardScaler().fit(X_train)\n","# X_train = scaler.transform(X_train)\n","# X_test= scaler.transform(X_test)\n","\n","clf = MLPClassifier(random_state=0, max_iter=300, verbose = True,hidden_layer_sizes=(256,128),early_stopping = True)\n","\n","clf.fit(X_train, y_train)\n","predictions = clf.predict(X_test)\n","f1_score(y_test, predictions, average=None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VC2xHdX0VATr","executionInfo":{"status":"ok","timestamp":1664451049685,"user_tz":-600,"elapsed":15512,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"358bef61-a769-493c-a841-582569d53900"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 1, loss = 32.13853568\n","Validation score: 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 2, loss = 7.42118243\n","Validation score: 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 3, loss = 6.52791142\n","Validation score: 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 4, loss = 6.21514275\n","Validation score: 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 5, loss = 5.93867378\n","Validation score: 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 6, loss = 5.64699784\n","Validation score: 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 7, loss = 5.33466453\n","Validation score: 0.004464\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 8, loss = 5.00607056\n","Validation score: 0.007440\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 9, loss = 4.67577923\n","Validation score: 0.013393\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 10, loss = 4.36232164\n","Validation score: 0.019345\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 11, loss = 4.07337665\n","Validation score: 0.038690\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 12, loss = 3.80037379\n","Validation score: 0.055060\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 13, loss = 3.55884328\n","Validation score: 0.069940\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 14, loss = 3.32788803\n","Validation score: 0.075893\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 15, loss = 3.11420064\n","Validation score: 0.074405\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 16, loss = 2.92018186\n","Validation score: 0.083333\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 17, loss = 2.73406357\n","Validation score: 0.101190\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 18, loss = 2.55693627\n","Validation score: 0.105655\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 19, loss = 2.39097290\n","Validation score: 0.107143\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 20, loss = 2.23469073\n","Validation score: 0.114583\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 21, loss = 2.08301073\n","Validation score: 0.122024\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 22, loss = 1.94438881\n","Validation score: 0.123512\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 23, loss = 1.81249767\n","Validation score: 0.129464\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 24, loss = 1.68433278\n","Validation score: 0.138393\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 25, loss = 1.56440539\n","Validation score: 0.139881\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 26, loss = 1.45116612\n","Validation score: 0.148810\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 27, loss = 1.34168250\n","Validation score: 0.142857\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 28, loss = 1.24009142\n","Validation score: 0.160714\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 29, loss = 1.14718246\n","Validation score: 0.160714\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 30, loss = 1.04966854\n","Validation score: 0.160714\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 31, loss = 0.97054337\n","Validation score: 0.166667\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 32, loss = 0.88744617\n","Validation score: 0.165179\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 33, loss = 0.81340884\n","Validation score: 0.162202\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 34, loss = 0.74414406\n","Validation score: 0.157738\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 35, loss = 0.68060785\n","Validation score: 0.157738\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 36, loss = 0.62365710\n","Validation score: 0.153274\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 37, loss = 0.56687298\n","Validation score: 0.163690\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 38, loss = 0.52117480\n","Validation score: 0.163690\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 39, loss = 0.47416281\n","Validation score: 0.168155\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 40, loss = 0.43389151\n","Validation score: 0.159226\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 41, loss = 0.39524679\n","Validation score: 0.157738\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 42, loss = 0.36082144\n","Validation score: 0.159226\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 43, loss = 0.33131940\n","Validation score: 0.163690\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 44, loss = 0.30289817\n","Validation score: 0.163690\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 45, loss = 0.27687830\n","Validation score: 0.160714\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 46, loss = 0.25569995\n","Validation score: 0.162202\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 47, loss = 0.23435724\n","Validation score: 0.163690\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 48, loss = 0.21765940\n","Validation score: 0.168155\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 49, loss = 0.20019567\n","Validation score: 0.162202\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 50, loss = 0.18408829\n","Validation score: 0.166667\n","Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0.4516129 , 0.        , 0.        , 0.33333333, 0.54545455,\n","       0.        , 0.42105263, 0.53333333, 0.33333333, 0.25      ,\n","       0.27586207, 0.30769231, 0.26086957, 0.35294118, 0.57142857,\n","       0.58333333, 0.26086957, 0.2       , 0.        , 0.66666667,\n","       0.        , 0.75      , 0.        , 0.28571429, 0.        ,\n","       0.45454545, 0.48484848, 0.13333333, 0.6       , 0.        ,\n","       0.25      , 0.28571429, 0.46666667, 0.76190476, 0.2       ,\n","       0.        , 0.        , 0.70588235, 0.33333333, 0.30769231,\n","       0.33333333, 0.35294118, 0.        , 0.66666667, 0.57142857,\n","       0.76923077, 0.42857143, 0.62068966, 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.08333333, 0.        ,\n","       0.83333333, 0.4       , 0.4       , 0.        , 0.6       ,\n","       0.        , 0.57142857, 0.        , 0.44444444, 0.16666667,\n","       0.41666667, 0.30769231, 0.30769231, 0.        , 0.16666667,\n","       0.5       , 0.28571429, 0.16666667, 0.25      , 0.17391304,\n","       0.36363636, 0.5       , 0.14285714, 0.68571429, 0.54545455,\n","       0.        , 0.28571429, 0.58823529, 0.19047619, 0.25      ,\n","       0.71428571, 0.        , 0.        , 0.66666667, 0.33333333,\n","       0.52631579, 0.33333333, 0.57142857, 0.        , 0.2       ,\n","       0.14285714, 0.        , 0.4       , 0.4       , 0.        ])"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["f1_score(y_test, predictions, average='samples')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ii_PqYvEVd2S","executionInfo":{"status":"ok","timestamp":1664451052961,"user_tz":-600,"elapsed":312,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"94b80a81-a7a7-4e38-862d-771ddcdaa9ad"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.25974084003574616"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","source":["## MultiOutputClassifier"],"metadata":{"id":"NoQamYaVSoBZ"}},{"cell_type":"code","source":["base_lr = LogisticRegression(solver='liblinear', random_state=0,max_iter = 200)\n","scaler = preprocessing.StandardScaler().fit(X_train)\n","X_scaled_train = scaler.transform(X_train)\n","X_scaled_test= scaler.transform(X_test)\n","clf = MultiOutputClassifier(base_lr).fit(X_scaled_train, y_train)\n","predictions = clf.predict(X_scaled_test)\n","f1_score(y_test, predictions, average=None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tW2iEdSxRj8W","executionInfo":{"status":"ok","timestamp":1664439452195,"user_tz":-600,"elapsed":41363,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"136549db-8e25-4a5d-b497-8fbfa86781db"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.78947368, 0.5       , 0.28571429, 0.22222222, 0.61538462,\n","       0.28571429, 0.52173913, 0.70588235, 0.33333333, 0.4       ,\n","       0.375     , 0.58823529, 0.1875    , 0.4       , 0.88888889,\n","       0.54545455, 0.4       , 0.46153846, 0.4       , 0.66666667,\n","       0.        , 0.5       , 0.36363636, 0.375     , 0.        ,\n","       0.43478261, 0.47058824, 0.38095238, 0.26666667, 0.625     ,\n","       0.        , 0.4       , 0.62068966, 0.8       , 0.44444444,\n","       0.5       , 0.        , 0.45454545, 0.54545455, 0.23529412,\n","       0.53333333, 0.33333333, 0.4       , 0.85714286, 0.6       ,\n","       0.71428571, 0.22222222, 0.70967742, 0.        , 0.5       ,\n","       0.28571429, 0.28571429, 0.22222222, 0.36842105, 0.        ,\n","       0.90909091, 0.42857143, 0.73684211, 0.53333333, 0.63157895,\n","       0.66666667, 0.70588235, 0.2       , 0.66666667, 0.33333333,\n","       0.56      , 0.57142857, 0.4       , 0.28571429, 0.30769231,\n","       0.66666667, 0.33333333, 0.52631579, 0.22222222, 0.38461538,\n","       0.28571429, 0.66666667, 0.33333333, 0.85714286, 0.61538462,\n","       0.        , 0.44444444, 0.63636364, 0.5       , 0.4       ,\n","       0.8       , 0.4       , 0.4       , 0.        , 0.66666667,\n","       0.7826087 , 0.44444444, 0.58823529, 0.2       , 0.57142857,\n","       0.6       , 0.        , 0.11764706, 0.5       , 0.22222222])"]},"metadata":{},"execution_count":176}]},{"cell_type":"code","source":["f1_score(y_test, predictions, average='samples')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9JAKpo9ULp6","executionInfo":{"status":"ok","timestamp":1664439456393,"user_tz":-600,"elapsed":486,"user":{"displayName":"YU Weng","userId":"00576395625376478765"}},"outputId":"2a6040ab-dbb8-4c65-a0fb-afcabad848f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.40389378271415804"]},"metadata":{},"execution_count":178}]},{"cell_type":"markdown","source":["## Test set"],"metadata":{"id":"rlyRGDfNUNJu"}},{"cell_type":"code","source":["#Test\n","# Counts for sentences\n","sentences_voc = {}\n","sentences_num = 4999\n","for i in range(sentences_num):\n","  sentences_voc[str(i)] = i\n","\n","test_string_sentences = convert_to_string(df_test['sentences'])\n","test_sentences_vectorizer = CountVectorizer(vocabulary = sentences_voc)\n","test_sentences_counts = test_sentences_vectorizer.fit_transform(test_string_sentences).toarray()  \n","\n","# Counts for coauthors\n","coauthor_voc = {}\n","coauthor_num = 21246\n","for i in range(coauthor_num):\n","  coauthor_voc[str(i)] = i\n","\n","test_string_coauthor = convert_to_string(df_test['coauthors'])\n","test_coauthor_vectorizer = CountVectorizer(vocabulary = coauthor_voc)\n","test_coauthor_counts = coauthor_vectorizer.fit_transform(test_string_coauthor).toarray()\n","\n","\n","\n","test_coauthors_features_name = ['coauthors_' + str(i) for i in range(21246)]\n","# coauthors_features = np.vstack([coauthors_features_name,coauthors_ohe])\n","df_test_coauthors_features = pd.DataFrame(test_coauthor_counts)\n","df_test_coauthors_features = df_test_coauthors_features.astype('float')\n","df_test_coauthors_features.columns = test_coauthors_features_name\n","\n","test_sentence_features_name = ['sentences_' + str(i) for i in range(1,5000)]\n","df_test_sentence_features = pd.DataFrame(test_sentences_counts)\n","df_test_sentence_features = df_test_sentence_features.astype('float')\n","df_test_sentence_features.columns = test_sentence_features_name\n","\n","\n","df_test_merge_coauthors_sentences = pd.concat([df_test_coauthors_features, df_test_sentence_features], axis = 1)\n","\n","\n"],"metadata":{"id":"it9bKOYlHvk4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test_merge_coauthors_sentences"],"metadata":{"id":"32TulxWZOJnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_scaled_predict= scaler.transform(df_test_merge_coauthors_sentences)"],"metadata":{"id":"9OxteXUV7kph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predition = chain.predict(X_scaled_predict)"],"metadata":{"id":"hF1k53SD7kss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predition"],"metadata":{"id":"KFrpGlnJ7kvT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_list = [i.tolist() for i in predition]\n","total_index_list = []\n","for i in predicted_list:\n","  index_list = []\n","  for j,k in enumerate(i):\n","    if k == 1:\n","      index_list.append(str(j))\n","  if len(index_list) != 0:\n","    total_index_list.append(index_list)\n","  else:\n","    total_index_list.append([str(-1)])\n","\n","predicted_str = []\n","for i in total_index_list:\n","  a = ','.join(i)\n","  predicted_str.append(a)"],"metadata":{"id":"XCzb0yzf7kxw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","df_output = pd.DataFrame({'ID': list(range(800)),'Predict':predicted_str})\n","df_output.to_csv('predicted_result.csv',index = False)"],"metadata":{"id":"TQvc0-eI8J0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"76Cs4nI-8MJV"},"execution_count":null,"outputs":[]}]}